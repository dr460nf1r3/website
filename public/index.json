[{"content":"","date":null,"permalink":"/tags/chaotic-aur/","section":"Tags","summary":"","title":"chaotic-aur"},{"content":"","date":null,"permalink":"/tags/foss/","section":"Tags","summary":"","title":"foss"},{"content":"","date":null,"permalink":"/tags/garuda/","section":"Tags","summary":"","title":"garuda"},{"content":"","date":null,"permalink":"/tags/linux/","section":"Tags","summary":"","title":"linux"},{"content":"","date":null,"permalink":"/tags/open-source/","section":"Tags","summary":"","title":"open source"},{"content":"","date":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"The recent server migrations #First of all \u0026#x1f447; #Since people asked for a more detailed explanation and also for something like a dev blog, I figured I\u0026rsquo;d write down some of my thoughts and observations about the recent migration.\nWhy did we do this? \u0026#x1f440; #The Garuda infra has historically always been developing over time. Starting out with pure Docker-based setups, we quickly figured it would be beneficial to have a tool to manage configurations with. After TNE came up with Ansible, we set up our infra playbooks to manage the Arch-based servers. All of this was fine, and upgrading and managing, as well as saving the state to git repositories were quite significant advantages over manual server management.\nTime passes and we discovered NixOS as server OS. Now why choose another OS for the job? It\u0026rsquo;s simple, managing NixOS systems is even better than using Ansible due to its declarative nature (declarative = define it, tool executes it, imperative = entering commands to achieve settings). Not only would you define a system state and apply it, but changes would also be reverted in case of removing a part of a configuration - something Ansible does not do, it just applies the defined state. We fell in love with NixOS and the possibilities it provides. Bootstrapping an entire system including its configs is pretty much a matter of downloading the git repository with the configurations and running nixos-install.\nSo, we were running NixOS for infrastructure purposes for quite a while now. While we started out with a few VMs back in the day, we were having 1 dedicated server and 1 root server to host VMs / LXC containers for multiple purposes. They contained builders, web applications, the forum, and all the things we need to provide Garuda as is. As you can imagine, VMs are quite isolated from the host and use more resources than eg. having a Docker container. They take their own, fixed amount of RAM from the host and use the CPU to emulate the interfaces and devices. LXC containers on the other hand were more lightweight, as they share resources with each other and the host.\nFast forward to about a month ago - the contract for the root server is about to expire and it\u0026rsquo;s obvious that we could get much more value for the same amount of money by upgrading the dedicated server and replacing the root server with it. TNE and I planned to move our \u0026ldquo;host\u0026rdquo; part of the server to NixOS for a while already and this was the perfect time to execute the plan - given I had a week of vacation to spend on this.\nThe idea? \u0026#x1f914; #Now there were a lot of ideas and questions on how to solve specific problems. Resources should be used as efficiently as possible, while also containing all of our previous VMs/Containers. NixOS has a thing called nixos-containers, which are basically declarative (or imperative!) systemd-nspawn Containers running NixOS. They share the Nix store with the host (the Nix store being the thing making Nix Nix - all files, applications, and basically the whole operating system is located in this store, which are then being symlinked to the regular locations) and can be configured to be ephemeral, which means that the root filesystem is located in a temporary filesystem, which is being deleted on shutdown or restart. This means only locations or files we bind-mound from the host\u0026rsquo;s filesystem into the containers would survive a restart of the container and we would always have a \u0026ldquo;fresh\u0026rdquo; system. So we only keep things we want to keep, automatically clear the rest on restarts and share a lot of common resources between the host \u0026amp; containers while still having them isolated in some kind of way. It may be noticed that the goal here was not to achieve strict isolation - that would\u0026rsquo;ve meant not being able to run Docker or our Chaotic builder inside those containers.\nExecution \u0026#x1f527; #The first days of working on this consisted of writing the required Nix expressions to provide our containers. We came up with a custom function that builds our containers just the way we want them. Since we started out of a container supposed to be building Chaotic-AUR packages, we hit the first obstacle. The problem consisted of needing to run systemd-nspawn inside systemd-nspawn, since the toolbox utilizes it to build in a clean environment. This was eventually solved by mounting mounting /sys/fs/groups at the startup of the container. The next part of the implementation was getting Docker to run inside the nspawn containers. By default, we were not able to get Docker to run successfully - the solution consisted of providing additional capabilities and mounts to the container.\nWe opted for running everything Docker-based in one container, and everything native in separate ones. That means, that we are running 10 different containers for different purposes. The forum also runs in Docker, but since it did Discourse expects the installation in /var/discourse rather than where our custom NixOS module puts it, we choose to put it into its own container, too. All of this is behind the web-front container, which uses Nginx as reverse proxy, adding in SSL. Different containers are also in place for different repositories we distribute via Chaotic-AUR (chaotic-aur, garuda, and kde-git).\n‚ùØ machinectl MACHINE CLASS SERVICE OS VERSION ADDRESSES chaotic-kde container systemd-nspawn nixos 23.11 10.0.5.90‚Ä¶ docker container systemd-nspawn nixos 23.11 10.0.5.100‚Ä¶ forum container systemd-nspawn nixos 23.11 10.0.5.70‚Ä¶ iso-runner container systemd-nspawn nixos 23.11 10.0.5.40‚Ä¶ mastodon container systemd-nspawn nixos 23.11 10.0.5.80‚Ä¶ meshcentral container systemd-nspawn nixos 23.11 10.0.5.60‚Ä¶ postgres container systemd-nspawn nixos 23.11 10.0.5.50‚Ä¶ repo container systemd-nspawn nixos 23.11 10.0.5.30‚Ä¶ temeraire container systemd-nspawn nixos 23.11 10.0.5.20‚Ä¶ web-front container systemd-nspawn nixos 23.11 10.0.5.10‚Ä¶ 10 machines listed. Moving the data \u0026#x1f468;\u0026zwj;\u0026#x1f4bb; #The transition of all Chaotic-AUR services went quite painless, including the main node. After that, we started the main migration, which included all web services and their data. This was also the point, where the announced service disruptions occurred. The transfer of the data happened and most services were back after the estimated time frame had passed. Things still missing included Mastodon, which needed its database configuration fixed, Chaotic-AUR suddenly starting to misbehave after allocating ISO builds to it and Matrix bridges not being able to connect to the main instance. Though, after working on this for a whole day, it was time to sleep to not introduce additional issues due to being tired.\nThe next day consisted of fixing the remaining issues - mostly database configurations, a missing port forward of the Matrix federation port, and adjusting the webserver configuration of Discourse to the new environment to avoid rate limits. By now, all issues that were found are worked out.\nThe aftermath \u0026#x1f680; #After observing the system for the time being, we can say that things are considerably faster than before (loading forum pages is QUICK!), especially Chaotic-AUR builds since we are now able to build in RAM. One of the biggest advantages of this configuration turned out to be a disadvantage as well - the declarative nixos-containers. Since they would respond to every change of our configuration, changing a non-container-specific option would cause every container to be shut down and recreated, causing small downtimes of services. This should however not be an issue once the configuration is 100% completed.\nThings left to do? üßê #We quickly noticed Chaotic-AUR builds would hit the rate limit of AUR, which is a problem since builds for the most part rely on sourcing packages from AUR. Not being able to connect means that every build fails. Basically, it is the same issue that plagues Piped, Invidious, Searx, and Whoogle instances for quite a while (especially Piped and Invidious were striking the rate limit after deploying to the new server very quickly, so they are still out of order). Though, we are working on a possible solution that involves rotating IPv6 addresses of the /64 subnet that Hetzner provides to every server for outgoing requests. Initial attempts caused web services to be unreachable and we are still investigating the cause for this.\nConclusion \u0026#x1f30d; #This whole action was definitely a bigger operation than I expected at first, especially the transition of all the different web services, with more total downtime than anticipated. However, it also turned out to be a great learning opportunity and definitely provided a big enhancement to the performance of every component of Garuda\u0026rsquo;s web services. And at this point, I\u0026rsquo;d like to offer my sincere apologies for any inconvenience caused during the transition! I hope this provided some interesting insight into our current actions ‚ò∫\n","date":null,"permalink":"/projects/nix-infra/","section":"My favorite projects","summary":"This is a summary about the most recent major server maintenance we had at Garuda Linux / Chaotic-AUR \u0026#x1f527;","title":"Taking the infra's NixOS setup to the next level"},{"content":"","date":null,"permalink":"/tags/ansible/","section":"Tags","summary":"","title":"ansible"},{"content":"Introduction #As our infrastructure is growing, the number of services and tasks is increasing as well. This can be tedious and time-consuming, especially when you have to deal with a lot of servers - enter Ansible! Ansible allows automating tasks on a wide range of platforms, including Linux, Windows, and Mac. It is based on so-called playbooks, roles and tasks. Once defined, it is really easy to deploy the defined settings to target machines. All it needs is adding a few lines to the hosts file and defining host_vars to let Ansible know what kind of tasks to execute.\nStarting out #As I didn\u0026rsquo;t know much about Ansible before, I decided to study already existing playbooks in order to learn more about how it works. The Arch infrastructure repository helped me a lot in understanding how to set up the different roles needed. I began by writing a role for all kinds of common tasks like installing base packages, setting up services and installing a MOTD.\nHost_vars and conditionals to the rescue #Since not every host needs to be configured the same way, host_vars provides a neat way to define what task to execute on which machine. I also added a few conditionals to the role to make sure that certain tasks are only executed if needed - eg. Chaotic-AUR GPG keys don\u0026rsquo;t need to be fetched every time the playbook is executed. There was also one issue with our docker-compose configurations - as the repo was closed source previously, it contained a lot of sensible environment variables in those files. To make it open source, those variables needed to be replaced with Ansible variables. Thanks to the template feature of Ansible, it is quite easy to supply a template docker-compose.yml.j2 (Jinja2 formatting) which then gets rendered into a proper docker-compose.yml file with the variables replaced when the playbook is executed. Also, ansible-vault is a great little tool that allows encrypting sensitive files and data easily - Ansible automatically decrypts the content when deploying changes.\nAutomating everything! #While writing the different roles, I had so much fun that I couldn\u0026rsquo;t stop working on it until it was all automated. Ansible Galaxy also came in handy, as it provided an already existing playbook for basic hardening of Linux installations and SSH with the devsec.hardening collection. Meanwhile, I also rewrote our existing Nginx configurations to better fit our needs. Thinking about how I used Nginx Proxy Manager to handle web server needs not too long ago, I\u0026rsquo;m somewhat happy I finally learned how to do it properly. It just provides so much more flexibility concerning configurations and setup. While NPM worked fine for the time being, it feels really good to be able to write your own Nginx configurations!\nChaotic-AUR cluster bootstrap? #Well, since I\u0026rsquo;m also operating Chaotic-AUR, it was natural to also include it in the process of automating stuff. After a long trial and error session, the chaotic_aur role is now available on Chaotic\u0026rsquo;s Github organization. It is also available in Garuda\u0026rsquo;s infrastructure repository as a git submodule and can be used to set up a whole cluster if provided with the correct host_vars.\nThrowing in some GitLab CI #Automating and running playbooks on my personal machine was too boring, so I decided to utilize GitLab CI to trigger deployments based on commit messages. Currently, the repo responds to deploy \u0026lt;playbook.yml\u0026gt; as well as dry-run \u0026lt;playbook.yml\u0026gt;. Obviously deploy deploys the supplied playbook while the latter initiates a dry run via ansible-playbook \u0026lt;playbook.yml\u0026gt; --check.\nWrapping it all up #I had a great time learning how to use Ansible! It will be really useful to decrease time spent configuring servers, allowing me to focus on other things which aren\u0026rsquo;t automated. After all, changes just need to be pushed by ansible-playbook full_run.yml while setting up a new server became a matter of a few minutes.\n","date":null,"permalink":"/projects/ansible-infra/","section":"My favorite projects","summary":"As our infrastructure is growing, the number of services and tasks is increasing as well. This can be tedious and time-consuming, especially when you have to deal with a lot of servers - enter Ansible! Ansible allows automating tasks on a wide range of platforms, including Linux, Windows, and Mac. \u0026#x1f527;","title":"Ansible roles for the infra!"},{"content":"","date":null,"permalink":"/tags/arch/","section":"Tags","summary":"","title":"arch"},{"content":"","date":null,"permalink":"/tags/aur/","section":"Tags","summary":"","title":"aur"},{"content":"","date":null,"permalink":"/tags/browser/","section":"Tags","summary":"","title":"browser"},{"content":"What is Chaotic-AUR? \u0026#x1f440; #As Chaotic-AUR is the repository (kind of an app store for Linux distributions) of Garuda Linux and one of the user repositories with the most (and most useful) packages out there I decided to provide another mirror for it. Especially a massive increase in web traffic on the main server made this necessary! The repo can be accessed at mirrors.dr460nf1r3.org and can be found in the chaotic-mirrorlist package as well. \u0026#x1f4c3;\nWhat and how many packages does it provide? \u0026#x1f4e6; #Chaotic-AUR provides everyday applications such as Spotify, GitHub Desktop, Visual Studio Code Insiders, a variety of Linux-tkg kernels and a lot of other software which is not available in the official Arch repositories. The loss of the 380GB RAM main cluster in December 2020 made changes necessary and our Garuda builder became one of new three clusters to build individual packages for Chaotic-AUR. About 2630 of the previous over 4000 packages have been recovered until now and building packages is automated again! \u0026#x1f60a;\nHow does this server help Chaotic-AUR? \u0026#x1f4c8; #This server is also a Chaotic-AUR builder to help with compiling all those great packages which couldn\u0026rsquo;t have been updated daily otherwise! Currently, it builds the entire KDE/Plasma -git stack (bleeding edge, daily compiled packages), most of the stuff I use personally \u0026amp; some of the requested packages daily. Have a look here to have some insight \u0026#x1f60a;\n","date":null,"permalink":"/projects/chaotic-aur/","section":"My favorite projects","summary":"As Chaotic-AUR is the repository (kind of an app store for Linux distributions) of Garuda Linux and one of the user repositories with the most (and most useful) packages out there I decided to help with maintenance and provide another mirror for it. Especially a massive increase of web traffic on the main server made this necessary!","title":"Chaotic-AUR"},{"content":"","date":null,"permalink":"/tags/dr460nized/","section":"Tags","summary":"","title":"dr460nized"},{"content":"","date":null,"permalink":"/tags/firedragon/","section":"Tags","summary":"","title":"firedragon"},{"content":"The beginning of the journey üö∂‚Äç‚ôÇÔ∏è #For about 2 years I have been using Linux. Since the beginning, I loved the way things work on Linux, the simplicity and customizability - something unheard of among windows users. For a long time of these two years, I spent distro hopping, searching for the optimal Linux distribution for my requirements. For those of you who do know the term \u0026ldquo;distro hopping\u0026rdquo; - a very good explanation can be found here! As a result, I have tried countless Distributions like Ubuntu, Fedora, Arch and Gentoo in all kinds of forms. After a while I stuck with Gentoo - the customizability was just too great, turning features on and off at compile time with use flags? Hell yes. But there were two major drawbacks: The compile times on a dual-core CPU T440p were just too much (imagine Chromium taking 18 hours to compile) and to get all required software a lot of so-called \u0026ldquo;overlays\u0026rdquo; had to be used which made the system feel very messy to me at some point - a solution had to be found.\nEarly days of Garuda Linux \u0026#x1f476; #During these days I found myself trying out Garuda Linux. It emerged out of the custom Manjaro build called \u0026ldquo;Manjarowish\u0026rdquo; which implemented a lot of great things such as performance enhancements or OpenSUSE style BTRFS with automated snapshots before each update by default. Garuda takes this to another level running on top of pure Arch which means always the latest and greatest packages! Eventually, there was no maintainer for the GNOME edition at the time I was this edition for a short time - being completely new to this kind of business I decided to step in and maintain it (at this time Garuda was still rather unknown - the Telegram group had about 20 members back then). Since then many things changed - a lot of new ideas were implemented, existing tools improved, and the team welcomed new members and people like it so far since the feedback has been mostly pretty overwhelming!\nExpansion and new resources\u0026#x1f6b8; #Some time passed and the Garuda slowly grew. Everything I did was done using my hardware for quite some time - that changed when we were suggested to check out Fosshost, a project which provides all kinds of hosting services for open-source projects. Its goal is to \u0026ldquo;support, promote, and advance the development and movement of free software\u0026rdquo; which is kind of what we are trying to do with Garuda! Time before contributing to Garuda I was learning how to self-host a lot of open source projects including Searx and Nextcloud but sadly none of my people was actually interested in such things so this seemed like the perfect opportunity to do something useful with the knowledge I acquired.. After some brainstorming, we decided to apply for resources (needed them, especially for the forum \u0026amp; building - the cluster which it was running on before was possibly going to be shut down) and got them granted! This means we did not have to take donations to continue providing this distribution until now. There were three VPS for us to use, one to host web services like the website or Searx, one to build iso files (this one also builds packages for Chaotic-AUR now) and one to hold applications that require more storage (looking at you, Nextcloud). Also, the people behind Fosshost were really kind and helpful while migrating everything to their services - shoutouts to them!\nSetting everything up \u0026#x1f527; #After the initial setup of the servers (which I got helped with luckily, the Proxmox VNC window of the VMs was somewhat buggy and didn\u0026rsquo;t input the characters I needed) it was time to deploy the applications. This was quite fun and I noticed that it was indeed easy for me after having done countless trial \u0026amp; error sessions at my VPS earlier. The only thing which proved to be impossible to set up along with all other applications was Discourse, the forum software. This one comes with a complete installer that turns the system into a forum server and occupies both ports 80 and 443 (the ones needed for HTTP and HTTPS) which quite of interfered with NGINX, the proxy server used. Luckily Fosshost gave us one little instance to use for whatever we needed it for - indeed a lucky coincidence because it was perfect to run Discourse on! The migration from its previous location happened without issues. Inspired by the Fosshosts Telegram channel (which was bridged into Matrix, the first time I heard of it) I did some research on how to bridge our Telegram channel to a self-hosted Matrix instance as Matrix is an open-source and decentralized protocol which allows bridging into many known platforms - among them Telegram! Sounds like heaven for an open-source enthusiast who does not want companies to own his data? Well for me it did. Being new to Matrix it took some time to figure it all out but in the end, it worked quite well. Other things which were set up in the following month were a Telegram moderator bot (Rose - a great open-source and free bot) and all applications you can find here. This one also made it into Garudas browser settings as a start page! During this time we also transitioned from Garuda\u0026rsquo;s previous domain (.in) to the one we are using today (.org) which was accompanied by me having to learn how to properly forward a domain to another one (you need SSL certificates for both domains, which I did not know back then). But luckily help was not far away and this issue got solved quickly!\nThe future \u0026#x1f3c6; #A lot of things happened since that time, I really need to start documenting things again! Life sadly got super busy lately \u0026#x1f914;\n","date":null,"permalink":"/projects/garuda/","section":"My favorite projects","summary":"For about 2 years I have been using Linux. Since the beginning, I loved the way things work on Linux, the simplicity and customizability - something unheard of in among windows users. A long time of these two years I spent distro hopping, searching for the optimal Linux distribution for my requirements. \u0026#x1f985;","title":"Garuda Linux"},{"content":"","date":null,"permalink":"/tags/garuda-linux/","section":"Tags","summary":"","title":"garuda-linux"},{"content":"Intro #Hello everyone! \u0026#x1f468;\u0026zwj;\u0026#x1f4bb;\nThis is another post dedicated to recent changes to some of our infrastructure - this time tackling the repository setups, particularly those containing PKGBUILDs or sources for our packages \u0026#x1f527;\nMotivation #For those, who already worked with our git repos to contribute, as well as the ones who took a look at what the source of certain packages looks like, you might have noticed that we had a LOT of different repositories for all kinds of purposes. This also included repositories, which only inherited one PKGBUILD and its .install file. Treating things this way had a simple reason: the scripts used to build packages (chaotic-toolbox) only support custom Git sources that have the PKGBUILD right in the root of the cloned repository, which is just how the AUR does it.\nAfter having worked with this setup for quite a while, it became obvious that having all of the build recipes in one place would be a great improvement to everyone having to deal with multiple packages at once. Not only would this allow changing multiple PKGBUILD\u0026rsquo;s dependencies without having to do countless git operations (sure, those can be scripted. But why make it harder than it has to be?), but it also provides the possibility to perform the same actions for all PKGBUILDs easily. And not to forget, working with CI/CD pipelines is a task I enjoy a lot! ü§≠\nAdvantages and plans #These are some of the advantages in comparison to the situation we had before (the scope of this is the garuda repository, not the chaotic-aur one!):\nIt is easy to find the right repository and files for contributors, hopefully making a contribution more attractive than before It allows generating changelogs without looking at each repository (collecting those tends to be a tedious task!) It provides an entry point for syntax/anti-pattern checks of the code It makes reviewing PRs easier and faster since a suite of checks is automatically run against it, detecting the most obvious errors It enables us to use git for deployments - which now can be done by every maintainer of the Garuda team, rather than only by package maintainers and server admins It speeds up certain actions, such as updating the PKGBUILD to push a new version by automatically executing the required actions It allows enforcing a baseline of standards for code, which hasn\u0026rsquo;t been the case before All of these were implemented by now.\nWhat changed? #Let\u0026rsquo;s look at some of the changes and how they affect things.\nPKGBUILD location and where to edit files #This is a change that will be relevant for everyone who wants to contribute changes to packages and settings. Unlike before, there is now a single unified repository for all PKGBUILDs:\nhttps://gitlab.com/garuda-linux/pkgbuilds\nAs the description already suggests, some packages also have their sources included here. This applies to most packages, which consist of up to a few text files, like garuda-fish-config or garuda-hooks. The other ones are the ones that require more extensive source code or reference external repos (all packages not listed in the SOURCES file automatically belong to the first category). This means the following for changing files or reporting issues:\nPackaging matters should be implemented/reported in the PKGBUILDs repository Issues/changes to settings should be reported in their respective source repositories. For version bumps, this means:\nPackages of the first category get bumped via the PKGBUILDs repository, triggering an instant deployment by supplying [deploy $pkgname] in the commit message Packages of the second category just need a new tag in their source repositories to be pushed in case no packaging changes occur (which does not happen that often after all), the rest - updating PKGBUILD, checksums, triggering a build - will automatically be done by the PKGBUILDs CI pipeline! This also means that everyone can now inspect the build status for packages of the [garuda] repository by looking at the pipeline runs.\nGenerating changelogs #By adopting conventional commit messages with the Angular convention, another manual task could be automated. Changelogs are now automatically generated via commitizen. For each automated version update of packages of the before-mentioned second category, changelogs of the source repos are automatically attached to the commit message.\nThis however only works, if the commit message convention is used. Otherwise, commitizen is unable to parse them accordingly. To ensure this is always the case, another CI job checks whether commits comply with the format.\nFor contributors, this basically means using the correct commit messages. It may sound harder than it is. There would be a handful of most used formats:\nfix: xyz not working feat: add new waybar icon style(garuda-fish-config): improve spacing # Providing a scope like this would only be necessary for the PKGBUILDs repo to automatically track the package to which the commits are later accounted to Recommendations include:\nKeep the message short: Makes the list of commits more readable (~50 chars). Talk imperative Think about the CHANGELOG: Your commits will probably end up in the changelog so try writing for it, but also keep in mind that you can skip sending commits to the CHANGELOG by using different keywords (like build). Use a commit per new feature: if you introduce multiple things related to the same commit, squash them. This is useful for auto-generating CHANGELOG. The commitizen app is also able to interactively generate a complying commit message, so it can be a great help in case someone doesn\u0026rsquo;t want to spend time reading documentation.\nBasic syntax/style checks #Another great thing to be added to the new repository is checks against PKGBUILDs and other files. Every commit is checked for basic integrity with a set of linters (have a look at the script behind it) by a pipeline run:\nhttps://gitlab.com/garuda-linux/pkgbuilds/-/jobs/5487774423\nThis would give instant feedback about whether obvious issues exist with a commit, which may be corrected (such as not complying with conventional commits!). Hopefully, it also increases code quality on its way by a bit :D The script may be run locally via bash .ci/lint.sh, possibly even correcting some of the issues by passing an argument bash .ci/lint.sh apply (dependencies of course need to be installed).\nIf there are any other helpful tools in this regard, let me know! üòÑ\nImplementation #Well, the implementation mostly consisted of writing the required bash scripts, preparing the server to accept build requests (securing it properly on the way), and testing it. First, the linter script was implemented, followed by the deployment (since it checks first and only deploys if checks were successful) via commit message. After that, the version bumps were implemented. It turned out to be working better than I anticipated! After having the setup in a working state, all of our packages/source repositories were either deleted (the obsolete ones, before the content was moved to our archive of course) or had their PKGBUILD removed and a new README explaining where to find things and how to contribute added (the source repos mostly). Also, all package sources are now checked via sha256sums, some were either using md5sum or SKIP before. Existing PKGBUILDs needed issues reported by shellcheck/shfmt to be worked out before the CI would actually be useful. Of course, documentation had to be updated with a new repository section.\nLooking forward #Things are implemented and working quite well so far. I\u0026rsquo;m sure there will be some more bugs to be worked out, but so far, so good! A similar setup may be implemented on our iso-profiles repo, but for ISO builds \u0026#x1f604; I hope that my efforts to better document things via our infra docs, as well as to apply certain standards encourage more people (also on the infra side!) to contribute to our beloved project \u0026#x2764;\u0026#xfe0f;\nAs a positive side-effect our Telegram channel for GitLab updates is working again since I found Telegram notifications to be an inbuilt integration by now (it didn\u0026rsquo;t use to be?), the previous webhook solution we used seemingly got abandoned and wasn\u0026rsquo;t working reliably/at all.\nFurthermore, I\u0026rsquo;d love to make better use of GitLabs features, eg. by tracking current bigger tasks via Epics and corresponding issues. This should also provide a better insight into what we are currently up to for everyone who is interested in these matters.\nThat\u0026rsquo;s all for now, thanks for reading! \u0026#x1f917;\n","date":null,"permalink":"/projects/garuda-ci/","section":"My favorite projects","summary":"This is another post dedicated to recent changes to some of our infrastructure - this time tackling the repository setups, particularly those containing PKGBUILDs or sources for our packages \u0026#x1f527;","title":"Improving Garuda's repository set via CI/CD pipelines"},{"content":"","date":null,"permalink":"/tags/infrastructure/","section":"Tags","summary":"","title":"infrastructure"},{"content":"","date":null,"permalink":"/tags/pipelines/","section":"Tags","summary":"","title":"pipelines"},{"content":"","date":null,"permalink":"/tags/privacy/","section":"Tags","summary":"","title":"privacy"},{"content":"","date":null,"permalink":"/tags/repository/","section":"Tags","summary":"","title":"repository"},{"content":"Initial idea \u0026#x1f43a; #Recently we got to know that Mozilla no longer supports free internet. Their browser, Firefox, collects a lot of telemetry by default. Since using Chromium-based browsers is not an alternative (There shouldn\u0026rsquo;t be a single browser engine dictating web standards! \u0026#x1f440;), some people decided to step in and provide a better solution. Librewolf is a community-maintained project which removes the privacy-compromising parts and provides an additionally hardened browser config. That means no about:config tweaking is needed to get going - everything just works after opening the browser for the first time. It has a few drawbacks though: It does not integrate well into Garuda dr460nized and has too strict default settings for most people.\nCreating an alternative \u0026#x1f409; #When I found out that a talented Maintainer brought a PKGBUILD to AUR which can build Librewolf from Firefox\u0026rsquo;s nightly branch I was interested in using it! Even better, with some modifications, I was able to build a custom-branded version with my settings called FireDragon. The initial idea was to create a fork of librewolf-hg however this quickly changed when the Garuda forum got interested in a stable version as well. This fork ships saner defaults to also include regular (not paranoid \u0026#x1f60b;) users of Garuda Linux in its audience and ships with the searX search engine by default, some handpicked patches from Gentoo, Ubuntu \u0026amp; Debian and some useful add-ons. Of course, FireDragon is available at Chaotic-AUR - the nightly firedragon-hg package is even built daily from the latest source!\nNotable features \u0026#x1f525; #There are some features that I love about this browser:\nApp menu support thanks to Ubuntu patches Enhanced KDE integration thanks to OpenSUSE patches Better system library usage thanks to Gentoo patches Uses the self-hosted sync server of Garuda to sync the Mozilla account Uses the self-hosted Whoogle instance of Garuda as the default search engine ","date":null,"permalink":"/projects/firedragon/","section":"My favorite projects","summary":"Recently we got to know that Mozilla no longer supports free internet. Their browser, Firefox, collects a lot of telemetry by default. Since using Chromium-based browsers is not an alternative (There shouldn\u0026rsquo;t be a single browser engine dictating web standards! \u0026#x1f440;), a better solution had to be found!","title":"The FireDragon browser"},{"content":"Favorites \u0026#x2b50; # Searxng - Metasearch engine Whoogle - Privacy-friendly Google GitHub / GitLab - Managing projects Garuda Forum - Linux community My hosted stuff üñ• # Dragon Cloud - Nextcloud instance Nitter - Nitter instance Libreddit - Libreddit instance Project Links \u0026#x1f985; # Cloud - The Garuda Cloud Builds - Builds and logs Nginx logs - Nginx GoAccess page Development \u0026#x1f527; # Cloudflare - Domain management AUR - The Arch user repository ","date":null,"permalink":"/startpage/","section":"","summary":"Favorites \u0026#x2b50; # Searxng - Metasearch engine Whoogle - Privacy-friendly Google GitHub / GitLab - Managing projects Garuda Forum - Linux community My hosted stuff üñ• # Dragon Cloud - Nextcloud instance Nitter - Nitter instance Libreddit - Libreddit instance Project Links \u0026#x1f985; # Cloud - The Garuda Cloud Builds - Builds and logs Nginx logs - Nginx GoAccess page Development \u0026#x1f527; # Cloudflare - Domain management AUR - The Arch user repository ","title":""},{"content":"Who am I? #I\u0026rsquo;m a Linux and technology enthusiast from Germany who likes maintaining servers and all kinds of Linux-related things to learn more about how these things work inside. Wherever possible I\u0026rsquo;m trying to spread the word about open source and Linux! I\u0026rsquo;m also a developer at Garuda Linux as part of a team that is trying to provide a modern and performance-focused operating system for interested people, an activity I enjoy a lot for quite some time! Recently I also became the main maintainer of Chaotic-AUR (which also serves as our repo). Since the beginning of this journey, I could work with an amazing team and learned a lot while doing so! These days I mostly hang around at the Garuda Linux forum \u0026amp; Telegram to make sure everything is working as expected - feel free to come by \u0026#x1f44b;\nYes, music is also a big part of my life! #I felt like dropping some goodness here \u0026#x1f60b; Carnifex all the way! üíÄ\nMy hardware #My laptop is a Lenovo Slim 7, a great 14\u0026quot; device with a lot of power thanks to its 8-core AMD Ryzen 7 4800u. Even though this is a low-power CPU, it is relatively quick and provides amazing battery life. You might have guessed it already - its operating system is Garuda dr460nized! \u0026#x1f409;\nWhere is this website hosted? #This website is hosted on GitHub with automated deployment to Cloudflare pages these days.\n","date":null,"permalink":"/about-me/","section":"About me","summary":"Who am I? #I\u0026rsquo;m a Linux and technology enthusiast from Germany who likes maintaining servers and all kinds of Linux-related things to learn more about how these things work inside. Wherever possible I\u0026rsquo;m trying to spread the word about open source and Linux! I\u0026rsquo;m also a developer at Garuda Linux as part of a team that is trying to provide a modern and performance-focused operating system for interested people, an activity I enjoy a lot for quite some time!","title":"About me"},{"content":"","date":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories"},{"content":"","date":null,"permalink":"/tags/ci/cd/","section":"Tags","summary":"","title":"ci/cd"},{"content":" Here I\u0026rsquo;m going to present a few of my favorite projects! \u0026#x1f525; ","date":null,"permalink":"/projects/","section":"My favorite projects","summary":" Here I\u0026rsquo;m going to present a few of my favorite projects! \u0026#x1f525; ","title":"My favorite projects"},{"content":" This website serves as a personal blog and will be dealing with Linux and FOSS projects mostly \u0026#x1f985; For a few years, I have found a deep passion for open source and Linux. As I kept learning about the importance of FOSS ecosystems, I quickly got interested in self-hosting open-source alternatives and contributing to a few projects myself. That\u0026rsquo;s also how I got involved in the development of Garuda Linux.\nMy most recent project was writing Ansible roles for the whole Garuda Linux and Chaotic-AUR infrastructure. I\u0026rsquo;m really happy with how it turned out! \u0026#x1f60a; Some of the projects I maintain or contribute to: Garuda Linux Garuda Linux is an Arch-based Linux distribution that is both beautiful and easy to use. I\u0026rsquo;m mostly maintaining the infrastructure and a few editions. You can read more about it here. \u0026#x1f985;\nChaotic-AUR Chaotic-AUR is an Arch user repository that provides binary builds for roughly 3k packages, most of them being built hourly straight from AUR. As the lead maintainer, I\u0026rsquo;m in charge of handling the repository and coordinating work. Have a look at this page to find out more! \u0026#x1f601;\nNixOS \"dr460nixed\" flake I particularly enjoy maintaining my devices as well as the Garuda infrastructure, since they are both NixOS-driven. My setup is available as ISO with an installer, bringing this particular setup to everyone who likes it.\nFireDragon FireDragon is a Librewolf fork that focuses on providing a smoother user experience while keeping the important privacy tweaks. It also integrates quite well with some of our self-hosted services such as searX. Wanna know more about it? \u0026#x1f60b;\n","date":null,"permalink":"/","section":"Welcome to the lair üëã","summary":"This website serves as a personal blog and will be dealing with Linux and FOSS projects mostly \u0026#x1f985; For a few years, I have found a deep passion for open source and Linux. As I kept learning about the importance of FOSS ecosystems, I quickly got interested in self-hosting open-source alternatives and contributing to a few projects myself.","title":"Welcome to the lair üëã"}]